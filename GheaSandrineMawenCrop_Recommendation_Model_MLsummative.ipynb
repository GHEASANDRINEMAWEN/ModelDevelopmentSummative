{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained the dataset for my crop recommendation system from Kaggle. This dataset encompasses crucial information such as nitrogen (N), phosphorus (P), potassium (K), temperature, humidity, pH, rainfall, and the corresponding recommended crop. Kaggle, being a prominent platform for data science resources, facilitated access to this dataset, allowing me to explore and analyze the factors influencing crop recommendations for different conditions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The dataset includes several features (independent variables) that are likely to influence the choice of a suitable crop for cultivation. The features are listed as N (Nitrogen), P (Phosphorus), K (Potassium), temperature, humidity, pH, and rainfall. The \"label\" column is presumably the target variable, indicating the recommended crop.\n",
    "\n",
    "Here's a brief explanation of the features in your dataset:\n",
    "\n",
    "1. N (Nitrogen): The amount of nitrogen in the soil, an essential nutrient for plant growth.\n",
    "2. P (Phosphorus): The amount of phosphorus in the soil, another crucial nutrient for plant development.\n",
    "3. K (Potassium): The amount of potassium in the soil, which supports various plant functions.\n",
    "4. Temperature: The average temperature, which can significantly impact the types of crops that thrive in a given region.\n",
    "5. Humidity: The amount of moisture in the air, affecting the overall climate and crop suitability.\n",
    "6. pH: The acidity or alkalinity of the soil, which influences nutrient availability to plants.\n",
    "7. Rainfall: The amount of rainfall, a critical factor in agriculture as it affects water availability for crops.\n",
    "\n",
    "- The \"label\" column contains the recommended crop based on the specified conditions of nitrogen, phosphorus, potassium, temperature, humidity, pH, and rainfall. This dataset is valuable for training a machine learning model to predict the most suitable crops for specific combinations of these environmental factors. The goal would be to assist farmers in making informed decisions about crop selection based on their soil and climate conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data set\n",
    "df = pd.read_csv(\"Crop_recommendation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>20.879744</td>\n",
       "      <td>82.002744</td>\n",
       "      <td>6.502985</td>\n",
       "      <td>202.935536</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>21.770462</td>\n",
       "      <td>80.319644</td>\n",
       "      <td>7.038096</td>\n",
       "      <td>226.655537</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>23.004459</td>\n",
       "      <td>82.320763</td>\n",
       "      <td>7.840207</td>\n",
       "      <td>263.964248</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>26.491096</td>\n",
       "      <td>80.158363</td>\n",
       "      <td>6.980401</td>\n",
       "      <td>242.864034</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>20.130175</td>\n",
       "      <td>81.604873</td>\n",
       "      <td>7.628473</td>\n",
       "      <td>262.717340</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    N   P   K  temperature   humidity        ph    rainfall label\n",
       "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
       "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
       "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
       "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
       "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>107</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>26.774637</td>\n",
       "      <td>66.413269</td>\n",
       "      <td>6.780064</td>\n",
       "      <td>177.774507</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>99</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>27.417112</td>\n",
       "      <td>56.636362</td>\n",
       "      <td>6.086922</td>\n",
       "      <td>127.924610</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>118</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>24.131797</td>\n",
       "      <td>67.225123</td>\n",
       "      <td>6.362608</td>\n",
       "      <td>173.322839</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>117</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>26.272418</td>\n",
       "      <td>52.127394</td>\n",
       "      <td>6.758793</td>\n",
       "      <td>127.175293</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>104</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>23.603016</td>\n",
       "      <td>60.396475</td>\n",
       "      <td>6.779833</td>\n",
       "      <td>140.937041</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        N   P   K  temperature   humidity        ph    rainfall   label\n",
       "2195  107  34  32    26.774637  66.413269  6.780064  177.774507  coffee\n",
       "2196   99  15  27    27.417112  56.636362  6.086922  127.924610  coffee\n",
       "2197  118  33  30    24.131797  67.225123  6.362608  173.322839  coffee\n",
       "2198  117  32  34    26.272418  52.127394  6.758793  127.175293  coffee\n",
       "2199  104  18  30    23.603016  60.396475  6.779833  140.937041  coffee"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17600"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2200, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rice', 'maize', 'chickpea', 'kidneybeans', 'pigeonpeas',\n",
       "       'mothbeans', 'mungbean', 'blackgram', 'lentil', 'pomegranate',\n",
       "       'banana', 'mango', 'grapes', 'watermelon', 'muskmelon', 'apple',\n",
       "       'orange', 'papaya', 'coconut', 'cotton', 'jute', 'coffee'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of unique crops\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N                int64\n",
       "P                int64\n",
       "K                int64\n",
       "temperature    float64\n",
       "humidity       float64\n",
       "ph             float64\n",
       "rainfall       float64\n",
       "label           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The differtent data type of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the counts of unique values in the 'label' column of the DataFrame\n",
    "label_counts = df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N              0\n",
       "P              0\n",
       "K              0\n",
       "temperature    0\n",
       "humidity       0\n",
       "ph             0\n",
       "rainfall       0\n",
       "label          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chceking of the column has null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Normalize numerical features to bring them to a similar scale. This is important for algorithms \n",
    "# that are sensitive to the scale of input features, such as gradient-based methods.\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>ph</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.264286</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.345886</td>\n",
       "      <td>0.790267</td>\n",
       "      <td>0.466264</td>\n",
       "      <td>0.656458</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.364286</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.435850</td>\n",
       "      <td>0.790898</td>\n",
       "      <td>0.541123</td>\n",
       "      <td>0.593019</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.483221</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.535472</td>\n",
       "      <td>0.680354</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.429507</td>\n",
       "      <td>0.771782</td>\n",
       "      <td>0.539024</td>\n",
       "      <td>0.668406</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.635714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.358664</td>\n",
       "      <td>0.772442</td>\n",
       "      <td>0.456854</td>\n",
       "      <td>0.593810</td>\n",
       "      <td>rice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           N         P      K  temperature  humidity        ph  rainfall label\n",
       "0   0.642857  0.264286  0.190     0.345886  0.790267  0.466264  0.656458  rice\n",
       "13  0.664286  0.364286  0.155     0.435850  0.790898  0.541123  0.593019  rice\n",
       "14  0.671429  0.321429  0.160     0.483221  0.774648  0.535472  0.680354  rice\n",
       "17  0.650000  0.214286  0.170     0.429507  0.771782  0.539024  0.668406  rice\n",
       "20  0.635714  0.285714  0.155     0.358664  0.772442  0.456854  0.593810  rice"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify numerical columns in the DataFrame\n",
    "numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Calculate quartiles and IQR for numerical columns\n",
    "Q1 = df[numerical_columns].quantile(0.25)\n",
    "Q3 = df[numerical_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Filter out outliers in numerical columns\n",
    "df = df[~((df[numerical_columns] < (Q1 - 1.5 * IQR)) | (df[numerical_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']] = scaler.fit_transform(df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperating features and target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features from the DataFrame\n",
    "features = df[['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall']]\n",
    "\n",
    "# Extracting the target variable from the DataFrame\n",
    "target = df['label']\n",
    "\n",
    "# Extracting labels from the 'label' column of the DataFrame\n",
    "labels = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialzing empty lists to append all model's name and corresponding name\n",
    "acc = []\n",
    "model = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why did we pick this models\n",
    "\n",
    "I chose a variety of models for the crop recommendation system to leverage their unique strengths. The Decision Tree is great for its simplicity and ease of interpretation, which helps in understanding how different factors influence crop selection. GaussianNB is efficient and works well with a large number of features, making it suitable for processing complex agricultural data. SVC is robust and effective, especially for classifying data with clear margins of separation. Logistic Regression is straightforward and efficient for binary classification problems, which is helpful in certain crop decision scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree's Accuracy is:  97.17514124293785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       0.83      1.00      0.90        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       0.78      1.00      0.88        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       0.91      1.00      0.95        20\n",
      "       maize       1.00      0.85      0.92        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      0.57      0.73         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.00      0.00      0.00         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.97       354\n",
      "   macro avg       0.93      0.92      0.92       354\n",
      "weighted avg       0.97      0.97      0.97       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a Decision Tree Classifier instance\n",
    "# - 'criterion=\"entropy\"' means the quality of splits will be measured using entropy.\n",
    "# - 'random_state=2' ensures reproducibility of results.\n",
    "# - 'max_depth=5' limits the tree depth to prevent overfitting.\n",
    "DecisionTree = DecisionTreeClassifier(criterion=\"entropy\", random_state=2, max_depth=5)\n",
    "\n",
    "# Train the Decision Tree Classifier using the training data.\n",
    "DecisionTree.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Predict the labels for the test set.\n",
    "predicted_values = DecisionTree.predict(Xtest)\n",
    "\n",
    "# Calculate the accuracy score of the model on the test data.\n",
    "# Accuracy is the proportion of correct predictions.\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "# Append the accuracy score to the 'acc' list for later comparison or use.\n",
    "acc.append(x)\n",
    "\n",
    "# Append the model name to the 'model' list for reference.\n",
    "model.append('Decision Tree')\n",
    "\n",
    "# Print the accuracy of the Decision Tree Classifier.\n",
    "print(\"Decision Tree's Accuracy is: \", x * 100)\n",
    "\n",
    "# Print a detailed classification report showing the main classification metrics.\n",
    "# This includes metrics like precision, recall, f1-score for each class.\n",
    "print(classification_report(Ytest, predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall Accuracy (97.17514124293785%):\n",
    "\n",
    "This indicates that the model correctly predicted the class for 97.17% of the test dataset. It's a high accuracy rate, suggesting that the model is performing well in general.\n",
    "\n",
    "- Precision, Recall, and F1-Score for Each Class:\n",
    "\n",
    "These metrics are calculated for each unique class (like 'banana', 'blackgram', etc.) in your dataset.\n",
    "Precision is the ratio of correctly predicted positive observations to the total predicted positives. High precision relates to a low false positive rate.\n",
    "Recall (Sensitivity) is the ratio of correctly predicted positive observations to all observations in the actual class. It shows how many of the actual positives your model correctly identified.\n",
    "F1-Score is a weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. It's a good way to show that a class has a balance between precision and recall.\n",
    "For instance, for 'banana', precision, recall, and F1-score are all 1.00 (or 100%), indicating excellent performance for this class.\n",
    "\n",
    "- Performance for Each Class:\n",
    "\n",
    "For most classes, your model shows high precision and recall, resulting in high F1-scores (close to 1, or 100%).\n",
    "Notably, 'mothbeans' have a recall of 0.57, meaning the model is less effective at identifying all relevant instances of this class.\n",
    "'Rice' has a precision and recall of 0.00, indicating the model failed to correctly predict any instance of this class. This could be a point of concern and might need further investigation.\n",
    "Macro and Weighted Averages:\n",
    "\n",
    "Macro average calculates metrics for each class and finds their unweighted mean. This does not take label imbalance into account. Here, it's 0.93 for precision, 0.92 for recall, and 0.92 for F1-score.\n",
    "Weighted average calculates metrics for each class and finds their average weighted by the number of true instances for each class. It's more useful when dealing with class imbalance. Here, it's 0.97 for precision, 0.97 for recall, and 0.97 for F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score (Decision Tree)\n",
    "score = cross_val_score(DecisionTree, features, target,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94632768, 0.92937853, 0.89830508, 0.97167139, 0.94334278])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation results for the Decision Tree model indicate varying accuracy levels across different folds, with values ranging from 89.83% to 97.17%. This suggests that the model's performance fluctuates when exposed to different subsets of the training data. The relatively high accuracies across folds demonstrate that the Decision Tree model is generally effective in making accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "DT_pkl_filename = 'DecisionTree.pkl'\n",
    "# Open the file to save as pkl file\n",
    "DT_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(DecisionTree, DT_Model_pkl)\n",
    "# Close the pickle instances\n",
    "DT_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes's Accuracy is:  0.9943502824858758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       1.00      1.00      1.00        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       1.00      0.86      0.92        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      1.00      1.00        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      1.00      1.00         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.67      1.00      0.80         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.98      0.99      0.99       354\n",
      "weighted avg       1.00      0.99      0.99       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Gaussian Naive Bayes classifier from scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Import metrics for evaluation\n",
    "from sklearn import metrics\n",
    "# Import classification report for detailed classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a Gaussian Naive Bayes classifier object\n",
    "NaiveBayes = GaussianNB()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "NaiveBayes.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predicted_values = NaiveBayes.predict(Xtest)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "# Append accuracy and model name to lists for tracking\n",
    "acc.append(accuracy)\n",
    "model.append('Naive Bayes')\n",
    "\n",
    "# Print the accuracy of the Naive Bayes classifier\n",
    "print(\"Naive Bayes's Accuracy is: \", accuracy)\n",
    "\n",
    "# Print the classification report for detailed metrics\n",
    "print(classification_report(Ytest, predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Accuracy (99.43502824858758%):\n",
    "\n",
    "This indicates that the model correctly predicted the class for approximately 99.44% of the test dataset, which is an exceptionally high accuracy rate and suggests that the model is performing very well overall.\n",
    "\n",
    "- Precision, Recall, and F1-Score for Each Class:\n",
    "\n",
    "These metrics are calculated for each unique class in your dataset.\n",
    "For almost all classes, your model achieves perfect precision, recall, and F1-scores of 1.00, indicating it performs exceptionally well in correctly identifying these classes.\n",
    "The only exception is the 'rice' class, where the precision is 0.67, but the recall is 1.00. This means that while the model identifies all actual instances of 'rice' correctly (high recall), it also incorrectly labels some other instances as 'rice' (lower precision).\n",
    "The F1-score for 'rice' is 0.80, which is lower than 1.00 but still quite high, indicating a good balance between precision and recall for this class.\n",
    "\n",
    "- Macro and Weighted Averages:\n",
    "\n",
    "The Macro Average (calculated as the unweighted mean of the metrics for each class) is 0.98 for precision, 0.99 for recall, and 0.99 for F1-score. This suggests high overall performance across all classes, without considering class imbalance.\n",
    "The Weighted Average (calculated as the average weighted by the number of true instances for each class) is 1.00 for precision, 0.99 for recall, and 0.99 for F1-score, which again indicates excellent performance, especially when considering class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99152542, 0.98870056, 0.99435028, 0.98866856, 0.98583569])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (NaiveBayes)\n",
    "score = cross_val_score(NaiveBayes,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Guassian Naive Bayes demonstrates strong and consistent performance across various folds, with accuracy scores ranging from 98.58% to 99.44%. These results indicate the model's effectiveness in accurately classifying data instances, showcasing its reliability and robustness. The minimal variability in accuracy across different subsets of the training data suggests that the SVC generalizes well and maintains a high level of performance on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Guassian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "NB_pkl_filename = 'NBClassifier.pkl'\n",
    "# Open the file to save as pkl file\n",
    "NB_Model_pkl = open(NB_pkl_filename, 'wb')\n",
    "pickle.dump(NaiveBayes, NB_Model_pkl)\n",
    "# Close the pickle instances\n",
    "NB_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's Accuracy is:  0.9858757062146892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       0.83      1.00      0.90        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       0.93      1.00      0.97        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      0.95      0.97        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      0.86      0.92         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      0.90      0.95        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       1.00      0.75      0.86         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.99      0.97      0.98       354\n",
      "weighted avg       0.99      0.99      0.99       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import SVM classifier from scikit-learn\n",
    "from sklearn.svm import SVC\n",
    "# Import MinMaxScaler for data normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Import metrics for evaluation\n",
    "from sklearn import metrics\n",
    "# Import classification report for detailed classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a MinMaxScaler object and fit it on the training data\n",
    "norm = MinMaxScaler().fit(Xtrain)\n",
    "# Transform the training data using the fitted scaler\n",
    "X_train_norm = norm.transform(Xtrain)\n",
    "# Transform the testing data using the same scaler\n",
    "X_test_norm = norm.transform(Xtest)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel, degree 3, and regularization parameter C=1\n",
    "SVM = SVC(kernel='poly', degree=3, C=1)\n",
    "\n",
    "# Train the SVM classifier on the normalized training data\n",
    "SVM.fit(X_train_norm, Ytrain)\n",
    "\n",
    "# Make predictions on the normalized test data\n",
    "predicted_values = SVM.predict(X_test_norm)\n",
    "\n",
    "# Evaluate the accuracy of the SVM model\n",
    "accuracy = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "# Append accuracy and model name to lists for tracking\n",
    "acc.append(accuracy)\n",
    "model.append('SVM')\n",
    "\n",
    "# Print the accuracy of the SVM classifier\n",
    "print(\"SVM's Accuracy is: \", accuracy)\n",
    "\n",
    "# Print the classification report for detailed metrics\n",
    "print(classification_report(Ytest, predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Accuracy (98.58757062146892%):\n",
    "\n",
    "The model correctly predicted the class for about 98.59% of the test dataset. This is a very high accuracy rate, suggesting the model is performing exceptionally well.\n",
    "\n",
    "- Precision, Recall, and F1-Score for Each Class:\n",
    "\n",
    "The metrics are calculated for each unique class in your dataset.\n",
    "Precision is consistently high for most classes, indicating that when the model predicts a class, it is often correct.\n",
    "Recall varies slightly among classes. For instance, 'mothbeans' and 'rice' have lower recall rates of 0.86 and 0.75, respectively. This means the model is missing some actual instances of these classes.\n",
    "The F1-score combines precision and recall into a single metric. For most classes, the F1-score is very high, indicating a good balance between precision and recall. The lower F1-score for 'rice' (0.86) reflects the lower recall for this class.\n",
    "\n",
    "- Performance for Specific Classes:\n",
    "\n",
    "Classes like 'blackgram', 'jute', 'lentil', 'mothbeans', 'pigeonpeas', and 'rice' show some variation in either precision or recall, suggesting room for improvement in these areas.\n",
    "The lower precision for 'blackgram' (0.83) indicates that some other class instances are being misclassified as 'blackgram'.\n",
    "The lower recall for 'mothbeans' and 'rice' suggests these classes are not being identified accurately in all instances.\\\n",
    "\n",
    "- Macro and Weighted Averages:\n",
    "\n",
    "The Macro Average (unweighted mean of the metrics for each class) is 0.99 for precision, 0.97 for recall, and 0.98 for F1-score, indicating high performance across classes.\n",
    "The Weighted Average (average weighted by the number of true instances for each class) is 0.99 for precision, recall, and F1-score, again indicating excellent overall performance, especially when considering class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9519774 , 0.9519774 , 0.96045198, 0.96600567, 0.97733711])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (SVM)\n",
    "score = cross_val_score(SVM,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consistently performs well across various folds, with accuracy scores ranging from 95.20% to 97.73%. These results indicate a high level of accuracy and suggest that the model generalizes effectively to different subsets of the training data. The minimal variability in accuracy across folds suggests a robust and stable performance, demonstrating the model's reliability in making accurate predictions on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving trained SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained SVM classifier with Pickle\n",
    "SVM_pkl_filename = 'SVMClassifier.pkl'\n",
    "# Open the file to save as pkl file\n",
    "SVM_Model_pkl = open(SVM_pkl_filename, 'wb')\n",
    "pickle.dump(SVM, SVM_Model_pkl)\n",
    "# Close the pickle instances\n",
    "SVM_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression's Accuracy is:  0.9774011299435028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       0.82      0.95      0.88        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      0.96      0.98        26\n",
      "        jute       0.93      1.00      0.97        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       0.95      0.95      0.95        20\n",
      "       maize       0.95      1.00      0.98        20\n",
      "       mango       0.93      1.00      0.96        13\n",
      "   mothbeans       1.00      0.71      0.83         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      0.90      0.95        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       1.00      0.75      0.86         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.98       354\n",
      "   macro avg       0.98      0.96      0.97       354\n",
      "weighted avg       0.98      0.98      0.98       354\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Logistic Regression classifier from scikit-learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Import metrics for evaluation\n",
    "from sklearn import metrics\n",
    "# Import classification report for detailed classification metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create a Logistic Regression classifier with a specified random state for reproducibility\n",
    "LogReg = LogisticRegression(random_state=2)\n",
    "\n",
    "# Train the Logistic Regression classifier using the training data\n",
    "LogReg.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predicted_values = LogReg.predict(Xtest)\n",
    "\n",
    "# Evaluate the accuracy of the Logistic Regression model\n",
    "accuracy = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "# Append accuracy and model name to lists for tracking\n",
    "acc.append(accuracy)\n",
    "model.append('Logistic Regression')\n",
    "\n",
    "# Print the accuracy of the Logistic Regression classifier\n",
    "print(\"Logistic Regression's Accuracy is: \", accuracy)\n",
    "\n",
    "# Print the classification report for detailed metrics\n",
    "print(classification_report(Ytest, predicted_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall Accuracy (97.74011299435028%):\n",
    "\n",
    "This means that the model correctly predicted about 97.74% of the test data. This is a very high accuracy rate and suggests that the model is generally performing well.\n",
    "\n",
    "- Precision, Recall, and F1-Score for Each Class:\n",
    "\n",
    "Precision and Recall are high for most classes, indicating the model's effectiveness in correctly identifying these classes.\n",
    "Precision refers to the proportion of true positive predictions among all positive predictions. For example, 'blackgram' has a precision of 0.82, meaning there are some instances where other classes might be misclassified as 'blackgram'.\n",
    "Recall measures how well the model identifies all actual instances of a class. For 'mothbeans', the recall is 0.71, indicating the model misses about 29% of the actual 'mothbeans' instances.\n",
    "The F1-score is the harmonic mean of precision and recall. A high F1-score (close to 1) for a class means the model has a good balance of precision and recall for that class.\n",
    "\n",
    "- Performance on Specific Classes:\n",
    "\n",
    "Most classes have high precision, recall, and F1-scores. However, there are a few exceptions:\n",
    "'Blackgram' has slightly lower precision.\n",
    "'Cotton' has slightly lower recall.\n",
    "'Mothbeans' and 'rice' have notably lower recall, indicating these classes are not identified correctly in all instances.\n",
    "\n",
    "- Macro and Weighted Averages:\n",
    "\n",
    "The Macro Average is 0.98 for precision, 0.96 for recall, and 0.97 for F1-score, indicating overall high performance across classes without considering class imbalance.\n",
    "The Weighted Average is 0.98 for precision, recall, and F1-score, taking into account the number of instances in each class. This also indicates excellent overall performance, especially in the context of class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96327684, 0.96045198, 0.97740113, 0.96600567, 0.98300283])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score (Logistic Regression)\n",
    "score = cross_val_score(LogReg,features,target,cv=5)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model consistently performs well, achieving accuracy scores ranging from 96.05% to 98.30%. This indicates a robust and reliable performance across different subsets of the training data. The minimal variability in accuracy across folds suggests that the model generalizes effectively and maintains a high level of accuracy on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving trained Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Dump the trained Naive Bayes classifier with Pickle\n",
    "LR_pkl_filename = '../models/LogisticRegression.pkl'\n",
    "# Open the file to save as pkl file\n",
    "LR_Model_pkl = open(DT_pkl_filename, 'wb')\n",
    "pickle.dump(LogReg, LR_Model_pkl)\n",
    "# Close the pickle instances\n",
    "LR_Model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAHUCAYAAAD2uU8XAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABKcklEQVR4nO3deXRN5/7H8c+JzDIQU4JIShAq5qFoRYmahyoaNd4Y26qW3qLamlpXS4vSKjUkbmuqsShKlZha003QUtSsYqiSSKgh2b8/rJxfTxPkRCLJ7vu11lmrefazn/3d216aj2fv51gMwzAEAAAAAIAJOeR0AQAAAAAAZBdCLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAA2WTKlCmyWCyqVKlSTpeSJ124cEHDhg1TSEiIPDw85OrqqrJly+rVV1/V0aNHc7q8bBcVFSWLxaKTJ0/mdCkAkKdZDMMwcroIAADMqGrVqtq3b58k6ccff1SdOnVyuKK8Y9euXWrVqpUMw9CAAQNUt25dOTs76/Dhw/ryyy/1008/6cqVKzldZra6dOmSjh07pmrVqsnFxSWnywGAPIvQCwBANtizZ49q1aqlli1b6ptvvlGfPn30+eef53RZ6bp+/brc3d1zugyrhIQElS9fXk5OTtqxY4dKliyZps+SJUvUoUOHHKgu+924cUOurq6yWCw5XQoAmAKPNwMAkA1mz54tSXr//fdVr149LVy4UNevX0/T77ffflPfvn3l7+8vZ2dnFS9eXB06dNCFCxesfa5evarXX39dpUuXlouLi4oWLaoWLVrol19+kSRt3rxZFotFmzdvthn75MmTslgsioqKsrb17NlTHh4eOnDggJ555hl5enqqcePGkqQNGzaobdu2KlmypFxdXRUUFKR+/frp999/T1P3L7/8os6dO6tYsWJycXFRqVKl1L17d928eVMnT56Uo6Ojxo0bl2a/LVu2yGKxaPHixfe8djNnztT58+c1fvz4dAOvpDSBd+XKlapbt67c3d3l6empJk2a6IcffrDpM2rUKFksFu3fv18dO3aUt7e3fHx8NHjwYN25c0eHDx9Ws2bN5OnpqcDAQI0fP95m/9Tr/OWXX2rw4MHy9fWVm5ubQkNDFRMTY9N3z549Cg8PV2BgoNzc3BQYGKjOnTvr1KlTNv1SH2Fev369IiIiVKRIEbm7u+vmzZvpPt4cExOjVq1aqWjRonJxcVHx4sXVsmVLnT171trnzz//1JtvvqnHHntMzs7OKlGihF5++WVdvXrV5tiBgYFq1aqV1q1bp+rVq8vNzU3BwcGaM2fOPf9sACAvIvQCAJDFbty4oQULFqhWrVqqVKmSIiIidO3atTRB77ffflOtWrW0fPlyDR48WGvXrtXkyZPl7e1tfXT32rVrevLJJzVjxgz961//0qpVqzR9+nSVK1dOcXFxmarv1q1batOmjRo1aqSvv/5ao0ePliQdO3ZMdevW1Weffab169drxIgR2rlzp5588kndvn3buv++fftUq1Yt/fjjjxozZozWrl2rcePG6ebNm7p165YCAwPVpk0bTZ8+XcnJyTbH/uSTT1S8eHE9++yz96xv/fr1ypcvn1q3bp2h85k/f77atm0rLy8vLViwQLNnz9aVK1fUsGFDbdu2LU3/Tp06qUqVKlq6dKn69OmjSZMmadCgQWrXrp1atmyp5cuXq1GjRho6dKiWLVuWZv/hw4fr+PHjmjVrlmbNmqVz586pYcOGOn78uLXPyZMnVb58eU2ePFnffvutPvjgA8XFxalWrVrp/iNCRESEnJyc9MUXX2jJkiVycnJK0ycpKUlNmjTRhQsX9Omnn2rDhg2aPHmySpUqpWvXrkmSDMNQu3bt9OGHH6pbt2765ptvNHjwYM2dO1eNGjXSzZs3bcbct2+fXn/9dQ0aNEhff/21KleurF69emnLli0ZuvYAkCcYAAAgS/33v/81JBnTp083DMMwrl27Znh4eBhPPfWUTb+IiAjDycnJOHjw4D3HGjNmjCHJ2LBhwz37bNq0yZBkbNq0yab9xIkThiQjMjLS2tajRw9DkjFnzpz7nkNKSopx+/Zt49SpU4Yk4+uvv7Zua9SokVGgQAHj4sWLD6xp+fLl1rbffvvNcHR0NEaPHn3fYwcHBxu+vr737ZMqOTnZKF68uBESEmIkJydb269du2YULVrUqFevnrVt5MiRhiTjo48+shmjatWqhiRj2bJl1rbbt28bRYoUMdq3b5/mnKpXr26kpKRY20+ePGk4OTkZvXv3vmedd+7cMRITE438+fMbH3/8sbU9MjLSkGR07949zT6p206cOGEYhmHs2bPHkGSsWLHinsdZt26dIckYP368TfuiRYsMScbnn39ubQsICDBcXV2NU6dOWdtu3Lhh+Pj4GP369bvnMQAgr2GmFwCALDZ79my5ubkpPDxckuTh4aGOHTtq69atNqsOr127Vk8//bQqVKhwz7HWrl2rcuXKKSwsLEtrfO6559K0Xbx4Uf3795e/v78cHR3l5OSkgIAASdKhQ4ck3X3/Nzo6Wp06dVKRIkXuOX7Dhg1VpUoVffrpp9a26dOny2KxqG/fvll2HocPH9a5c+fUrVs3OTj8/681Hh4eeu655/Tjjz+meay8VatWNj9XqFBBFotFzZs3t7Y5OjoqKCgozePIkvTCCy/YvG8bEBCgevXqadOmTda2xMREDR06VEFBQXJ0dJSjo6M8PDyUlJRkvZZ/ld6fx98FBQWpYMGCGjp0qKZPn66DBw+m6fP9999LuvsY+1917NhR+fPn18aNG23aq1atqlKlSll/dnV1Vbly5dI9bwDIqwi9AABkoV9//VVbtmxRy5YtZRiGrl69qqtXr1rfQf3r+5KXLl265zur9vSxl7u7u7y8vGzaUlJS9Mwzz2jZsmUaMmSINm7cqF27dunHH3+UdPeRbUm6cuWKkpOTM1TTwIEDtXHjRh0+fFi3b9/WzJkz1aFDB/n6+t53v1KlSunSpUtKSkp64DEuX74sSfLz80uzrXjx4kpJSUmzyrOPj4/Nz87OznJ3d5erq2ua9j///DPNuOnV7+vra61FuhuMP/nkE/Xu3Vvffvutdu3apd27d6tIkSLWa/lX6dX/d97e3oqOjlbVqlU1fPhwPf744ypevLhGjhxpffz88uXLcnR0TPMPEhaLJU2NklSoUKE0x3FxcUm3RgDIqwi9AABkoTlz5sgwDC1ZskQFCxa0flq2bClJmjt3rvU91yJFitgsQJSejPRJDWt/f18zvXdHJaW7KvBPP/2kffv2acKECXrllVfUsGFD1apVK00o8vHxUb58+R5Yk3Q3+BUqVEiffvqpFi9erPPnz+vll19+4H5NmzZVcnKyVq1a9cC+qfWl937zuXPn5ODgoIIFCz5wHHucP38+3bbUWuLj47V69WoNGTJEw4YNU+PGjVWrVi2FhITojz/+SHfMjK7UHBISooULF+ry5cuKjY3V888/rzFjxuijjz6SdPd63LlzR5cuXbLZzzAMnT9/XoULF7bnVAHAFAi9AABkkeTkZM2dO1dlypTRpk2b0nxef/11xcXFae3atZKk5s2ba9OmTTp8+PA9x2zevLmOHDlifWw1PYGBgZKk/fv327SvXLkyw7Wnhq6/fx/sjBkzbH5OXa148eLF9wzVqVxdXdW3b1/NnTtXEydOVNWqVVW/fv0H1tKrVy/5+vpqyJAh+u2339Ltk7rAVPny5VWiRAnNnz9fxl++hTEpKUlLly61ruiclRYsWGBzrFOnTmnHjh1q2LChpLvX0jCMNNdy1qxZaRb2yiyLxaIqVapo0qRJKlCggP73v/9JknUl7i+//NKm/9KlS5WUlGTdDgD/JI45XQAAAGaxdu1anTt3Th988IE1AP1VpUqV9Mknn2j27Nlq1aqVdeXjBg0aaPjw4QoJCdHVq1e1bt06DR48WMHBwXrttde0aNEitW3bVsOGDVPt2rV148YNRUdHq1WrVnr66afl6+ursLAwjRs3TgULFlRAQIA2btyY7srD9xIcHKwyZcpo2LBhMgxDPj4+WrVqlTZs2JCm78SJE/Xkk0+qTp06GjZsmIKCgnThwgWtXLlSM2bMkKenp7XvSy+9pPHjx2vv3r2aNWtWhmrx9vbW119/rVatWqlatWoaMGCA6tatK2dnZx09elRffvml9u3bp/bt28vBwUHjx49Xly5d1KpVK/Xr1083b97UhAkTdPXqVb3//vsZvgYZdfHiRT377LPq06eP4uPjNXLkSLm6uurNN9+UJHl5ealBgwaaMGGCChcurMDAQEVHR2v27NkqUKBApo+7evVqTZs2Te3atVPp0qVlGIaWLVumq1evqkmTJpKkJk2aqGnTpho6dKgSEhJUv3597d+/XyNHjlS1atXUrVu3rLgEAJC35NwaWgAAmEu7du0MZ2fn+65qHB4ebjg6Ohrnz583DMMwzpw5Y0RERBi+vr6Gk5OTUbx4caNTp07GhQsXrPtcuXLFePXVV41SpUoZTk5ORtGiRY2WLVsav/zyi7VPXFyc0aFDB8PHx8fw9vY2unbtal3t9++rN+fPnz/d2g4ePGg0adLE8PT0NAoWLGh07NjROH36tCHJGDlyZJq+HTt2NAoVKmQ4OzsbpUqVMnr27Gn8+eefacZt2LCh4ePjY1y/fj0jl9Hq/PnzxtChQ43HH3/ccHd3N1xcXIygoCCjX79+xoEDB2z6rlixwqhTp47h6upq5M+f32jcuLGxfft2mz6pqzdfunTJpv1e1yQ0NNR4/PHHrT+nrt78xRdfGAMHDjSKFCliuLi4GE899ZSxZ88em33Pnj1rPPfcc0bBggUNT09Po1mzZsZPP/1kBAQEGD169LD2S12heffu3WmO//fVm3/55Rejc+fORpkyZQw3NzfD29vbqF27thEVFWWz340bN4yhQ4caAQEBhpOTk+Hn52e8+OKLxpUrV2z6BQQEGC1btkz3vENDQ9O0A0BeZTGMvzyfAwAAkIUuXryogIAAvfLKKxo/fnxOl/NQNm/erKefflqLFy+2LkwGAMj9eLwZAABkubNnz+r48eOaMGGCHBwc9Oqrr+Z0SQCAfygWsgIAAFlu1qxZatiwoX7++WfNmzdPJUqUyOmSAAD/UDzeDAAAAAAwLWZ6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqs3ow8IyUlRefOnZOnp6csFktOlwMAAAAghxiGoWvXrql48eJycLj/XC6hF3nGuXPn5O/vn9NlAAAAAMglzpw5o5IlS963D6EXeYanp6ekuze2l5dXDlcDAAAAIKckJCTI39/fmhHuh9CLPCP1kWYvLy9CLwAAAIAMvfbIQlYAAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIuvLEKeU6raUFnyueR0GQAAAECeceXI5JwuIccw0wsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1Cby4RGBioyZMnZ3lfAAAAAPgnI/TeR8+ePWWxWGSxWOTk5KRixYqpSZMmmjNnjlJSUrL0WLt371bfvn2zvG9m/PW87/UBAAAAgLyA0PsAzZo1U1xcnE6ePKm1a9fq6aef1quvvqpWrVrpzp07WXacIkWKyN3dPcv7ZsbHH3+suLg460eSIiMj07SlunXrVrbVAgAAAAAPg9D7AC4uLvL19VWJEiVUvXp1DR8+XF9//bXWrl2rqKgoa7/4+Hj17dtXRYsWlZeXlxo1aqR9+/bZjLVy5UrVrFlTrq6uKly4sNq3b2/d9vdHlkeNGqVSpUrJxcVFxYsX18CBA+/Z9/Tp02rbtq08PDzk5eWlTp066cKFCzZjVa1aVV988YUCAwPl7e2t8PBwXbt2Ld1z9vb2lq+vr/UjSQUKFLD+HB4ergEDBmjw4MEqXLiwmjRpIkk6ePCgWrRoIQ8PDxUrVkzdunXT77//bh3XMAyNHz9epUuXlpubm6pUqaIlS5Zk/A8DAAAAAOxE6M2ERo0aqUqVKlq2bJmku2GuZcuWOn/+vNasWaO9e/eqevXqaty4sf744w9J0jfffKP27durZcuWiomJ0caNG1WzZs10x1+yZIkmTZqkGTNm6OjRo1qxYoVCQkLS7WsYhtq1a6c//vhD0dHR2rBhg44dO6bnn3/ept+xY8e0YsUKrV69WqtXr1Z0dLTef//9TF+DuXPnytHRUdu3b9eMGTMUFxen0NBQVa1aVXv27NG6det04cIFderUybrP22+/rcjISH322Wf6+eefNWjQIHXt2lXR0dHpHuPmzZtKSEiw+QAAAACAPRxzuoC8Kjg4WPv375ckbdq0SQcOHNDFixfl4uIiSfrwww+1YsUKLVmyRH379tXYsWMVHh6u0aNHW8eoUqVKumOfPn1avr6+CgsLk5OTk0qVKqXatWun2/e7777T/v37deLECfn7+0uSvvjiCz3++OPavXu3atWqJUlKSUlRVFSUPD09JUndunXTxo0bNXbs2Eydf1BQkMaPH2/9ecSIEapevbr+85//WNvmzJkjf39/HTlyRCVKlNDEiRP1/fffq27dupKk0qVLa9u2bZoxY4ZCQ0PTHGPcuHE21wsAAAAA7MVMbyYZhmFd0Gnv3r1KTExUoUKF5OHhYf2cOHFCx44dkyTFxsaqcePGGRq7Y8eOunHjhkqXLq0+ffpo+fLl93x/+NChQ/L397cGXkmqWLGiChQooEOHDlnbAgMDrYFXkvz8/HTx4kW7zzvV32ep9+7dq02bNtmcf3BwsKS7s8wHDx7Un3/+qSZNmtj0+e9//2u9Rn/35ptvKj4+3vo5c+ZMpusFAAAA8M/ETG8mHTp0SI899piku7Oofn5+2rx5c5p+BQoUkCS5ublleGx/f38dPnxYGzZs0HfffaeXXnpJEyZMUHR0tJycnGz6/jV836/97/tZLJaHWoE6f/78Nj+npKSodevW+uCDD9L09fPz008//STp7mPeJUqUsNmeOjv+dy4uLvfcBgAAAAAZQejNhO+//14HDhzQoEGDJEnVq1fX+fPn5ejoqMDAwHT3qVy5sjZu3Kh//etfGTqGm5ub2rRpozZt2ujll19WcHCwDhw4oOrVq9v0q1ixok6fPq0zZ85YZ3sPHjyo+Ph4VahQIfMnaafq1atr6dKlCgwMlKNj2tuqYsWKcnFx0enTp9N9lBkAAAAAsgOh9wFu3ryp8+fPKzk5WRcuXNC6des0btw4tWrVSt27d5ckhYWFqW7dumrXrp0++OADlS9fXufOndOaNWvUrl071axZUyNHjlTjxo1VpkwZhYeH686dO1q7dq2GDBmS5phRUVFKTk5WnTp15O7uri+++EJubm4KCAhI0zcsLEyVK1dWly5dNHnyZN25c0cvvfSSQkND77lQVnZ4+eWXNXPmTHXu3FlvvPGGChcurF9//VULFy7UzJkz5enpqX//+98aNGiQUlJS9OSTTyohIUE7duyQh4eHevTo8chqBQAAAPDPwTu9D7Bu3Tr5+fkpMDBQzZo106ZNmzRlyhR9/fXXypcvn6S7jwqvWbNGDRo0UEREhMqVK6fw8HCdPHlSxYoVkyQ1bNhQixcv1sqVK1W1alU1atRIO3fuTPeYBQoU0MyZM1W/fn3rDPGqVatUqFChNH0tFotWrFihggULqkGDBgoLC1Pp0qW1aNGi7Lso6ShevLi2b9+u5ORkNW3aVJUqVdKrr74qb29vOTjcvc3effddjRgxQuPGjVOFChXUtGlTrVq1yvqYOAAAAABkNYthGEZOFwFkREJCgry9veVdur8s+XjXFwAAAMioK0cm53QJWSo1G8THx8vLy+u+fZnpBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGk55nQBgL1Ox3wgLy+vnC4DAAAAQB7ATC8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMyzGnCwDs9cVzleXmyL/XAAAAAI9KxNrjOV1CppEcAAAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6c4GGDRvqtddey+kyAAAAAMB0CL2Z1LNnT1ksFr3//vs27StWrJDFYrFrrGXLlundd9/NyvLSSK039VOoUCE1a9ZM+/fvz9bjAgAAAEBOIvQ+BFdXV33wwQe6cuXKQ43j4+MjT0/PLKrq3po1a6a4uDjFxcVp48aNcnR0VKtWrbL9uAAAAACQUwi9DyEsLEy+vr4aN27cPftcvnxZnTt3VsmSJeXu7q6QkBAtWLDAps9fH29+88039cQTT6QZp3Llyho5cqT158jISFWoUEGurq4KDg7WtGnTHlivi4uLfH195evrq6pVq2ro0KE6c+aMLl26ZO0zdOhQlStXTu7u7ipdurTeeecd3b59W5J08uRJOTg4aM+ePTbjTp06VQEBATIMQ5J08OBBtWjRQh4eHipWrJi6deum33//3dp/yZIlCgkJkZubmwoVKqSwsDAlJSU9sH4AAAAAsBeh9yHky5dP//nPfzR16lSdPXs23T5//vmnatSoodWrV+unn35S37591a1bN+3cuTPd/l26dNHOnTt17Ngxa9vPP/+sAwcOqEuXLpKkmTNn6q233tLYsWN16NAh/ec//9E777yjuXPnZrj2xMREzZs3T0FBQSpUqJC13dPTU1FRUTp48KA+/vhjzZw5U5MmTZIkBQYGKiwsTJGRkTZjRUZGWh+fjouLU2hoqKpWrao9e/Zo3bp1unDhgjp16iRJiouLU+fOnRUREaFDhw5p8+bNat++vTUw/9XNmzeVkJBg8wEAAAAAe1iM9NIGHqhnz566evWqVqxYobp166pixYqaPXu2VqxYoWeffTbdEJeqZcuWqlChgj788ENJd2d6q1atqsmTJ0uSqlSpog4dOuidd96RJA0fPlzfffeddu3aJUkqVaqUPvjgA3Xu3Nk65nvvvac1a9Zox44d96z3yy+/lKurqyQpKSlJfn5+Wr16tapXr37PWidMmKBFixZZZ3e/+uor9e/fX3FxcXJxcdG+fftUrVo1HT9+XIGBgRoxYoR27typb7/91jrG2bNn5e/vr8OHDysxMVE1atTQyZMnFRAQcN9rPGrUKI0ePTpN+ydhAXJz5N9rAAAAgEclYu3xnC7BRkJCgry9vRUfHy8vL6/79iU5ZIEPPvhAc+fO1cGDB9NsS05O1tixY1W5cmUVKlRIHh4eWr9+vU6fPn3P8bp06aJ58+ZJkgzD0IIFC6yzvJcuXdKZM2fUq1cveXh4WD/vvfeezexwep5++mnFxsYqNjZWO3fu1DPPPKPmzZvr1KlT1j5LlizRk08+KV9fX3l4eOidd96xqbVdu3ZydHTU8uXLJUlz5szR008/rcDAQEnS3r17tWnTJpvagoODJUnHjh1TlSpV1LhxY4WEhKhjx46aOXPmPd+JfvPNNxUfH2/9nDlz5r7nBwAAAAB/R+jNAg0aNFDTpk01fPjwNNs++ugjTZo0SUOGDNH333+v2NhYNW3aVLdu3brneC+88IKOHDmi//3vf9qxY4fOnDmj8PBwSVJKSoqku484pwbY2NhY/fTTT/rxxx/vW2f+/PkVFBSkoKAg1a5dW7Nnz1ZSUpJmzpwpSfrxxx8VHh6u5s2ba/Xq1YqJidFbb71lU6uzs7O6deumyMhI3bp1S/Pnz1dERIR1e0pKilq3bm1TW2xsrI4ePaoGDRooX7582rBhg9auXauKFStq6tSpKl++vE6cOJGmXhcXF3l5edl8AAAAAMAejjldgFm8//77qlq1qsqVK2fTvnXrVrVt21Zdu3aVdDcUHj16VBUqVLjnWCVLllSDBg00b9483bhxQ2FhYSpWrJgkqVixYipRooSOHz9unf3NLIvFIgcHB924cUOStH37dgUEBOitt96y9vnrLHCq3r17q1KlSpo2bZpu376t9u3bW7dVr15dS5cuVWBgoBwd07+9LBaL6tevr/r162vEiBEKCAjQ8uXLNXjw4Ic6HwAAAAD4O0JvFgkJCVGXLl00depUm/agoCAtXbpUO3bsUMGCBTVx4kSdP3/+vqFXuvuI86hRo3Tr1i3rQlKpRo0apYEDB8rLy0vNmzfXzZs3tWfPHl25cuW+wfHmzZs6f/68JOnKlSv65JNPlJiYqNatW1trPX36tBYuXKhatWrpm2++sT7G/FcVKlTQE088oaFDhyoiIkJubm7WbS+//LJmzpypzp0764033lDhwoX166+/auHChZo5c6b27NmjjRs36plnnlHRokW1c+dOXbp06YHXAwAAAAAyg8ebs9C7776bZgGrd955R9WrV1fTpk3VsGFD+fr6ql27dg8cq2PHjrp8+bKuX7+epn/v3r01a9YsRUVFKSQkRKGhoYqKitJjjz123zHXrVsnPz8/+fn5qU6dOtq9e7cWL16shg0bSpLatm2rQYMGacCAAapatap27NhhXUzr73r16qVbt27ZPNosScWLF9f27duVnJyspk2bqlKlSnr11Vfl7e0tBwcHeXl5acuWLWrRooXKlSunt99+Wx999JGaN2/+wGsCAAAAAPZi9WZkytixY7Vw4UIdOHDgkR0zdYU2Vm8GAAAAHi1Wb8Y/RmJionbv3q2pU6dq4MCBOV0OAAAAANwXoRd2GTBggJ588kmFhoamebQZAAAAAHIbFrKCXaKiohQVFZXTZQAAAABAhjDTCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATMvR3h0uX76sESNGaNOmTbp48aJSUlJstv/xxx9ZVhwAAAAAAA/D7tDbtWtXHTt2TL169VKxYsVksViyoy4AAAAAAB6a3aF327Zt2rZtm6pUqZId9QAAAAAAkGXsfqc3ODhYN27cyI5aAAAAAADIUnaH3mnTpumtt95SdHS0Ll++rISEBJsPAAAAAAC5hd2PNxcoUEDx8fFq1KiRTbthGLJYLEpOTs6y4gAAAAAAeBh2h94uXbrI2dlZ8+fPZyErAAAAAECuZnfo/emnnxQTE6Py5ctnRz0AAAAAAGQZu9/prVmzps6cOZMdtQAAAAAAkKXsnul95ZVX9Oqrr+qNN95QSEiInJycbLZXrlw5y4oDAAAAAOBh2B16n3/+eUlSRESEtc1isbCQFQAAAAAg17E79J44cSI76gAAAAAAIMvZHXoDAgKyow4AAAAAALKc3aFXko4cOaLNmzfr4sWLSklJsdk2YsSILCkMAAAAAICHZXfonTlzpl588UUVLlxYvr6+Nt/Ta7FYCL0AAAAAgFzD7tD73nvvaezYsRo6dGh21AMAAAAAQJax+3t6r1y5oo4dO2ZHLQAAAAAAZCm7Q2/Hjh21fv367KgFAAAAAIAslaHHm6dMmWL976CgIL3zzjv68ccfFRISIicnJ5u+AwcOzNoKAQAAAADIJIthGMaDOj322GMZG8xi0fHjxx+6KCA9CQkJ8vb21idhAXJztPshBQAAAACZFLE2d+W81GwQHx8vLy+v+/bN0EzviRMnsqQwAAAAAAAeJbtXbx4zZoz+/e9/y93d3ab9xo0bmjBhAl9ZhGzXben+B/5rDgAAAABIGXy8+a/y5cunuLg4FS1a1Kb98uXLKlq0qJKTk7O0QCCVPY8wAAAAADAve7KB3S9GGoYhi8WSpn3fvn3y8fGxdzgAAAAAALJNhh9vLliwoCwWiywWi8qVK2cTfJOTk5WYmKj+/ftnS5EAAAAAAGRGhkPv5MmTZRiGIiIiNHr0aHl7e1u3OTs7KzAwUHXr1s2WIgEAAAAAyIwMh94ePXpIuvv1RfXq1Uvz/bwAAAAAAOQ2GQq9CQkJ1peDq1Wrphs3bujGjRvp9mWBIQAAAABAbpGh0FuwYEHris0FChRIdyGr1AWuWL0ZAAAAAJBbZCj0fv/999aVmTdt2pStBQEAAAAAkFUyFHpDQ0MlSXfu3NHmzZsVEREhf3//bC0MAAAAAICHZdf39Do6OurDDz/kEWYAAAAAQJ5gV+iVpMaNG2vz5s3ZUAoAAAAAAFkrw19ZlKp58+Z688039dNPP6lGjRrKnz+/zfY2bdpkWXEAAAAAADwMi2EYhj07ODjce3KY1ZuRnRISEuTt7a34+Hi+GgsAAAD4B7MnG9g905uSkpLpwgAAAAAAeJTsfqcXAAAAAIC8IlOhNzo6Wq1bt1ZQUJDKli2rNm3aaOvWrVldGwAAAAAAD8Xu0Pvll18qLCxM7u7uGjhwoAYMGCA3Nzc1btxY8+fPz44aAQAAAADIFLsXsqpQoYL69u2rQYMG2bRPnDhRM2fO1KFDh7K0QCAVC1kBAAAAkOzLBnaHXhcXF/38888KCgqyaf/1119VqVIl/fnnn/ZXDGRA6o1dskdpOTjny+lyAAAAANM59fmRnC4hQ+wJvXY/3uzv76+NGzemad+4caP8/f3tHQ4AAAAAgGxj91cWvf766xo4cKBiY2NVr149WSwWbdu2TVFRUfr444+zo0YAAAAAADLF7tD74osvytfXVx999JG++uorSXff8120aJHatm2b5QUCAAAAAJBZdodeSXr22Wf17LPPZnUtAAAAAABkqUx9Ty8AAAAAAHmB3TO9BQsWlMViSdNusVjk6uqqoKAg9ezZU//617+ypEAAAAAAADLL7tA7YsQIjR07Vs2bN1ft2rVlGIZ2796tdevW6eWXX9aJEyf04osv6s6dO+rTp0921AwAAAAAQIbYHXq3bdum9957T/3797dpnzFjhtavX6+lS5eqcuXKmjJlCqEXAAAAAJCj7H6n99tvv1VYWFia9saNG+vbb7+VJLVo0ULHjx9/+OoAAAAAAHgIdodeHx8frVq1Kk37qlWr5OPjI0lKSkqSp6fnw1cHAAAAAMBDsPvx5nfeeUcvvviiNm3apNq1a8tisWjXrl1as2aNpk+fLknasGGDQkNDs7xYAAAAAADsYXfo7dOnjypWrKhPPvlEy5Ytk2EYCg4OVnR0tOrVqydJev3117O8UAAAAAAA7GV36JWk+vXrq379+lldCwAAAAAAWSpDoTchISHDA3p5eWW6GAAAAAAAslKGQm+BAgVksVju28cwDFksFiUnJ2dJYQAAAAAAPKwMhd5NmzZlaLCYmJiHKgYAAAAAgKyUodB7v5WY4+PjNW/ePM2aNUv79u3Ta6+9llW1AQAAAADwUOz+nt5U33//vbp27So/Pz9NnTpVLVq00J49e7KyNgAAAAAAHopdqzefPXtWUVFRmjNnjpKSktSpUyfdvn1bS5cuVcWKFbOrRgAAAAAAMiXDM70tWrRQxYoVdfDgQU2dOlXnzp3T1KlTs7M2AAAAAAAeSoZnetevX6+BAwfqxRdfVNmyZbOzJgAAAAAAskSGZ3q3bt2qa9euqWbNmqpTp44++eQTXbp0KTtrAwAAAADgoWQ49NatW1czZ85UXFyc+vXrp4ULF6pEiRJKSUnRhg0bdO3ateysEwAAAAAAu9m9erO7u7siIiK0bds2HThwQK+//rref/99FS1aVG3atMmOGgEAAAAAyJRMf2WRJJUvX17jx4/X2bNntWDBgqyqCQAAAACALPFQoTdVvnz51K5dO61cuTIrhgMAAAAAIEtkSegFAAAAACA3IvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CL9J18eJF9evXT6VKlZKLi4t8fX3VtGlTRUdHq3DhwnrvvffS3W/cuHEqXLiwbt26paioKFksFlWoUCFNv6+++koWi0WBgYHZfCYAAAAA/skIvUjXc889p3379mnu3Lk6cuSIVq5cqYYNGyoxMVFdu3ZVVFSUDMNIs19kZKS6desmZ2dnSVL+/Pl18eJF/fDDDzb95syZo1KlSj2ScwEAAADwz+WY0wUg97l69aq2bdumzZs3KzQ0VJIUEBCg2rVrS5JKlSqljz/+WFu2bLFul6StW7fq6NGj6tWrl7XN0dFRL7zwgubMmaO6detKks6ePavNmzdr0KBBWrBgwSM8MwAAAAD/NMz0Ig0PDw95eHhoxYoVunnzZprtISEhqlWrliIjI23a58yZo9q1a6tSpUo27b169dKiRYt0/fp1SVJUVJSaNWumYsWK3beOmzdvKiEhweYDAAAAAPYg9CINR0dHRUVFae7cuSpQoIDq16+v4cOHa//+/dY+ERERWrJkiRITEyVJiYmJWrx4sc0sb6qqVauqTJkyWrJkiQzDUFRUlCIiIh5Yx7hx4+Tt7W39+Pv7Z91JAgAAAPhHIPQiXc8995zOnTunlStXqmnTptq8ebOqV6+uqKgoSVLnzp2VkpKiRYsWSZIWLVokwzAUHh6e7ngRERGKjIxUdHS0EhMT1aJFiwfW8Oabbyo+Pt76OXPmTJadHwAAAIB/BkIv7snV1VVNmjTRiBEjtGPHDvXs2VMjR46UJHl7e6tDhw7WR5wjIyPVoUMHeXl5pTtWly5d9OOPP2rUqFHq3r27HB0f/Dq5i4uLvLy8bD4AAAAAYA9CLzKsYsWKSkpKsv7cq1cvbd++XatXr9b27dvTfbQ5lY+Pj9q0aaPo6OgMPdoMAAAAAFmB0Is0Ll++rEaNGunLL7/U/v37deLECS1evFjjx49X27Ztrf1CQ0MVFBSk7t27KygoSA0aNLjvuFFRUfr9998VHByc3acAAAAAAJL4yiKkw8PDQ3Xq1NGkSZN07Ngx3b59W/7+/urTp4+GDx9u0zciIkLDhw/XG2+88cBx3dzc5Obmll1lAwAAAEAaFsMwjJwuAsiIhIQEeXt7q2SP0nJwzpfT5QAAAACmc+rzIzldQoakZoP4+PgHrv3D480AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0CL0AAAAAANMi9AIAAAAATIvQCwAAAAAwLUIvAAAAAMC0HHO6AMBeP0+JkZeXV06XAQAAACAPYKYXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGk55nQBgL3eDQqQi4Mlp8sAAAAA8qz3zv+R0yU8Msz0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMi9ALAAAAADAtQi8AAAAAwLQIvQAAAAAA0yL0AgAAAABMy/ShNzAwUJMnT870/lFRUSpQoECW1WMmDRs21GuvvZbTZQAAAADAPeVo6O3Zs6fatWuXrcfYvXu3+vbtm6G+6QXk559/XkeOHMn08aOiomSxWKyfYsWKqXXr1vr5558zPWZusWzZMr377rs5XQYAAAAA3JPpZ3qLFCkid3f3TO/v5uamokWLPlQNXl5eiouL07lz5/TNN98oKSlJLVu21K1btx5q3Ae5fft2to7v4+MjT0/PbD0GAAAAADyMXB16o6OjVbt2bbm4uMjPz0/Dhg3TnTt3rNuvXbumLl26KH/+/PLz89OkSZPSPHL799nbUaNGqVSpUnJxcVHx4sU1cOBASXcf1T116pQGDRpknZWV0n+8eeXKlapZs6ZcXV1VuHBhtW/f/r7nYbFY5OvrKz8/P9WsWVODBg3SqVOndPjwYWufHTt2qEGDBnJzc5O/v78GDhyopKQk6/a4uDi1bNlSbm5ueuyxxzR//vw052axWDR9+nS1bdtW+fPn13vvvSdJWrVqlWrUqCFXV1eVLl1ao0ePtrmO97omkjRt2jSVLVtWrq6uKlasmDp06GDd9vdrfeXKFXXv3l0FCxaUu7u7mjdvrqNHj1q3p17Lb7/9VhUqVJCHh4eaNWumuLi4+14/AAAAAMisXBt6f/vtN7Vo0UK1atXSvn379Nlnn2n27NnWICdJgwcP1vbt27Vy5Upt2LBBW7du1f/+9797jrlkyRJNmjRJM2bM0NGjR7VixQqFhIRIuvuobsmSJTVmzBjFxcXdM4h98803at++vVq2bKmYmBht3LhRNWvWzPB5Xb16VfPnz5ckOTk5SZIOHDigpk2bqn379tq/f78WLVqkbdu2acCAAdb9unfvrnPnzmnz5s1aunSpPv/8c128eDHN+CNHjlTbtm114MABRURE6Ntvv1XXrl01cOBAHTx4UDNmzFBUVJTGjh37wGuyZ88eDRw4UGPGjNHhw4e1bt06NWjQ4J7n1rNnT+3Zs0crV67UDz/8IMMw1KJFC5sZ5+vXr+vDDz/UF198oS1btuj06dP697//ne54N2/eVEJCgs0HAAAAAOzhmNMF3Mu0adPk7++vTz75RBaLRcHBwTp37pyGDh2qESNGKCkpSXPnztX8+fPVuHFjSVJkZKSKFy9+zzFPnz4tX19fhYWFycnJSaVKlVLt2rUl3X1UN1++fPL09JSvr+89xxg7dqzCw8M1evRoa1uVKlXuey7x8fHy8PCQYRi6fv26JKlNmzYKDg6WJE2YMEEvvPCCdda0bNmymjJlikJDQ/XZZ5/p5MmT+u6777R7925rwJ41a5bKli2b5lgvvPCCIiIirD9369ZNw4YNU48ePSRJpUuX1rvvvqshQ4Zo5MiR970mp0+fVv78+dWqVSt5enoqICBA1apVS/ccjx49qpUrV2r79u2qV6+eJGnevHny9/fXihUr1LFjR0l3H7mePn26ypQpI0kaMGCAxowZk+6Y48aNs7nOAAAAAGCvXDvTe+jQIdWtW9f6mLEk1a9fX4mJiTp79qyOHz+u27dvWwOaJHl7e6t8+fL3HLNjx466ceOGSpcurT59+mj58uU2j/lmRGxsrDVkZ5Snp6diY2O1d+9ea+CbPn26dfvevXsVFRUlDw8P66dp06ZKSUnRiRMndPjwYTk6Oqp69erWfYKCglSwYME0x/r7rPPevXs1ZswYm7H79OmjuLg4Xb9+/b7XpEmTJgoICFDp0qXVrVs3zZs3zxra/+7QoUNydHRUnTp1rG2FChVS+fLldejQIWubu7u7NfBKkp+fX7oz1pL05ptvKj4+3vo5c+bM/S4zAAAAAKSRa0OvYRg2gTe1Tbr77upf/zu9Punx9/fX4cOH9emnn8rNzU0vvfSSGjRoYNeCT25ubhnum8rBwUFBQUEKDg5Wv3791K1bNz3//PPW7SkpKerXr59iY2Otn3379uno0aMqU6bMPc8pvfb8+fPb/JySkqLRo0fbjH3gwAEdPXpUrq6u970mnp6e+t///qcFCxbIz89PI0aMUJUqVXT16tUM1ZLa/tc/o9RHulP99c/y71xcXOTl5WXzAQAAAAB75NrQW7FiRe3YscMmEO3YsUOenp4qUaKEypQpIycnJ+3atcu6PSEhwWbhpPS4ubmpTZs2mjJlijZv3qwffvhBBw4ckCQ5OzsrOTn5vvtXrlxZGzdufIgzkwYNGqR9+/Zp+fLlkqTq1avr559/VlBQUJqPs7OzgoODdefOHcXExFjH+PXXX9MNn39XvXp1HT58ON2xHRzu/vHf75o4OjoqLCxM48eP1/79+3Xy5El9//33aY5TsWJF3blzRzt37rS2Xb58WUeOHFGFChUe5nIBAAAAQKbl+Du98fHxio2NtWnz8fHRSy+9pMmTJ+uVV17RgAEDdPjwYY0cOVKDBw+Wg4ODPD091aNHD73xxhvy8fFR0aJFNXLkSDk4OKSZ/U0VFRWl5ORk1alTR+7u7vriiy/k5uamgIAASXdXet6yZYvCw8Pl4uKiwoULpxlj5MiRaty4scqUKaPw8HDduXNHa9eu1ZAhQzJ8zl5eXurdu7dGjhypdu3aaejQoXriiSf08ssvq0+fPsqfP78OHTqkDRs2aOrUqQoODlZYWJj69u2rzz77TE5OTnr99dfl5uZ2z3NNNWLECLVq1Ur+/v7q2LGjHBwctH//fh04cEDvvffefa/J6tWrdfz4cTVo0EAFCxbUmjVrlJKSku4j5GXLllXbtm3Vp08fzZgxQ56enho2bJhKlCihtm3bZvjaAAAAAEBWyvGZ3s2bN6tatWo2nxEjRqhEiRJas2aNdu3apSpVqqh///7q1auX3n77beu+EydOVN26ddWqVSuFhYWpfv36qlChglxdXdM9VoECBTRz5kzVr1/fOmO7atUqFSpUSJI0ZswYnTx5UmXKlFGRIkXSHaNhw4ZavHixVq5cqapVq6pRo0Y2s5sZ9eqrr+rQoUNavHixKleurOjoaB09elRPPfWUqlWrpnfeeUd+fn7W/v/9739VrFgxNWjQQM8++6z69OkjT0/Pe55rqqZNm2r16tXasGGDatWqpSeeeEITJ060Bv37XZMCBQpo2bJlatSokSpUqKDp06drwYIFevzxx9M9VmRkpGrUqKFWrVqpbt26MgxDa9asSfNIMwAAAAA8Khbjfi/B5jFJSUkqUaKEPvroI/Xq1Suny8lWZ8+elb+/v7777ju7F9bKqxISEuTt7a1/FykgF4f7z3ADAAAAuLf3zv+R0yU8lNRsEB8f/8C1f3L88eaHERMTo19++UW1a9dWfHy89atvzPg47ffff6/ExESFhIQoLi5OQ4YMUWBg4H2/NxcAAAAA/unydOiVpA8//FCHDx+Ws7OzatSooa1bt6b7Lm5ed/v2bQ0fPlzHjx+Xp6en6tWrp3nz5vHoMAAAAADch6keb4a58XgzAAAAkDX+SY835/hCVgAAAAAAZBdCLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CLwAAAADAtAi9AAAAAADTIvQCAAAAAEzLMacLAOz1zq+n5OXlldNlAAAAAMgDmOkFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACmRegFAAAAAJgWoRcAAAAAYFqEXgAAAACAaRF6AQAAAACm5ZjTBQAZZRiGJCkhISGHKwEAAACQk1IzQWpGuB9CL/KMy5cvS5L8/f1zuBIAAAAAucG1a9fk7e193z6EXuQZPj4+kqTTp08/8MYGMiIhIUH+/v46c+aMvLy8croc5HHcT8hq3FPIStxPyGo5fU8ZhqFr166pePHiD+xL6EWe4eBw9xV0b29v/rJGlvLy8uKeQpbhfkJW455CVuJ+QlbLyXsqoxNhLGQFAAAAADAtQi8AAAAAwLQIvcgzXFxcNHLkSLm4uOR0KTAJ7ilkJe4nZDXuKWQl7idktbx0T1mMjKzxDAAAAABAHsRMLwAAAADAtAi9AAAAAADTIvQCAAAAAEyL0AsAAAAAMC1CL3KVadOm6bHHHpOrq6tq1KihrVu33rd/dHS0atSoIVdXV5UuXVrTp09/RJUir7Dnnlq2bJmaNGmiIkWKyMvLS3Xr1tW33377CKtFbmfv31Gptm/fLkdHR1WtWjV7C0SeY+89dfPmTb311lsKCAiQi4uLypQpozlz5jyiapHb2Xs/zZs3T1WqVJG7u7v8/Pz0r3/9S5cvX35E1SI327Jli1q3bq3ixYvLYrFoxYoVD9wnN/9eTuhFrrFo0SK99tpreuuttxQTE6OnnnpKzZs31+nTp9Ptf+LECbVo0UJPPfWUYmJiNHz4cA0cOFBLly59xJUjt7L3ntqyZYuaNGmiNWvWaO/evXr66afVunVrxcTEPOLKkRvZez+lio+PV/fu3dW4ceNHVCnyiszcU506ddLGjRs1e/ZsHT58WAsWLFBwcPAjrBq5lb3307Zt29S9e3f16tVLP//8sxYvXqzdu3erd+/ej7hy5EZJSUmqUqWKPvnkkwz1z/W/lxtALlG7dm2jf//+Nm3BwcHGsGHD0u0/ZMgQIzg42KatX79+xhNPPJFtNSJvsfeeSk/FihWN0aNHZ3VpyIMyez89//zzxttvv22MHDnSqFKlSjZWiLzG3ntq7dq1hre3t3H58uVHUR7yGHvvpwkTJhilS5e2aZsyZYpRsmTJbKsReZMkY/ny5fftk9t/L2emF7nCrVu3tHfvXj3zzDM27c8884x27NiR7j4//PBDmv5NmzbVnj17dPv27WyrFXlDZu6pv0tJSdG1a9fk4+OTHSUiD8ns/RQZGaljx45p5MiR2V0i8pjM3FMrV65UzZo1NX78eJUoUULlypXTv//9b924ceNRlIxcLDP3U7169XT27FmtWbNGhmHowoULWrJkiVq2bPkoSobJ5Pbfyx1zugBAkn7//XclJyerWLFiNu3FihXT+fPn093n/Pnz6fa/c+eOfv/9d/n5+WVbvcj9MnNP/d1HH32kpKQkderUKTtKRB6Smfvp6NGjGjZsmLZu3SpHR/53C1uZuaeOHz+ubdu2ydXVVcuXL9fvv/+ul156SX/88Qfv9f7DZeZ+qlevnubNm6fnn39ef/75p+7cuaM2bdpo6tSpj6JkmExu/72cmV7kKhaLxeZnwzDStD2of3rt+Oey955KtWDBAo0aNUqLFi1S0aJFs6s85DEZvZ+Sk5P1wgsvaPTo0SpXrtyjKg95kD1/R6WkpMhisWjevHmqXbu2WrRooYkTJyoqKorZXkiy7346ePCgBg4cqBEjRmjv3r1at26dTpw4of79+z+KUmFCufn3cv7pGblC4cKFlS9fvjT/Gnnx4sU0/2qUytfXN93+jo6OKlSoULbVirwhM/dUqkWLFqlXr15avHixwsLCsrNM5BH23k/Xrl3Tnj17FBMTowEDBki6G1gMw5Cjo6PWr1+vRo0aPZLakTtl5u8oPz8/lShRQt7e3ta2ChUqyDAMnT17VmXLls3WmpF7ZeZ+GjdunOrXr6833nhDklS5cmXlz59fTz31lN57770cn5lD3pLbfy9nphe5grOzs2rUqKENGzbYtG/YsEH16tVLd5+6deum6b9+/XrVrFlTTk5O2VYr8obM3FPS3Rnenj17av78+bzXBCt77ycvLy8dOHBAsbGx1k///v1Vvnx5xcbGqk6dOo+qdORSmfk7qn79+jp37pwSExOtbUeOHJGDg4NKliyZrfUid8vM/XT9+nU5ONhGgXz58kn6/xk6IKNy/e/lObSAFpDGwoULDScnJ2P27NnGwYMHjddee83Inz+/cfLkScMwDGPYsGFGt27drP2PHz9uuLu7G4MGDTIOHjxozJ4923BycjKWLFmSU6eAXMbee2r+/PmGo6Oj8emnnxpxcXHWz9WrV3PqFJCL2Hs//R2rN+Pv7L2nrl27ZpQsWdLo0KGD8fPPPxvR0dFG2bJljd69e+fUKSAXsfd+ioyMNBwdHY1p06YZx44dM7Zt22bUrFnTqF27dk6dAnKRa9euGTExMUZMTIwhyZg4caIRExNjnDp1yjCMvPd7OaEXucqnn35qBAQEGM7Ozkb16tWN6Oho67YePXoYoaGhNv03b95sVKtWzXB2djYCAwONzz777BFXjNzOnnsqNDTUkJTm06NHj0dfOHIle/+O+itCL9Jj7z116NAhIywszHBzczNKlixpDB482Lh+/fojrhq5lb3305QpU4yKFSsabm5uhp+fn9GlSxfj7Nmzj7hq5EabNm267+9Eee33coth8PwCAAAAAMCceKcXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAPBQduzYoXz58qlZs2Y5XQoAAGlYDMMwcroIAACQd/Xu3VseHh6aNWuWDh48qFKlSuVIHbdv35aTk1OOHBsAkHsx0wsAADItKSlJX331lV588UW1atVKUVFRNttXrlypmjVrytXVVYULF1b79u2t227evKkhQ4bI399fLi4uKlu2rGbPni1JioqKUoECBWzGWrFihSwWi/XnUaNGqWrVqpozZ45Kly4tFxcXGYahdevW6cknn1SBAgVUqFAhtWrVSseOHbMZ6+zZswoPD5ePj4/y58+vmjVraufOnTp58qQcHBy0Z88em/5Tp05VQECAmCsAgLyH0AsAADJt0aJFKl++vMqXL6+uXbsqMjLSGgy/+eYbtW/fXi1btlRMTIw2btyomjVrWvft3r27Fi5cqClTpujQoUOaPn26PDw87Dr+r7/+qq+++kpLly5VbGyspLtBfPDgwdq9e7c2btwoBwcHPfvss0pJSZEkJSYmKjQ0VOfOndPKlSu1b98+DRkyRCkpKQoMDFRYWJgiIyNtjhMZGamePXvahG4AQN7gmNMFAACAvGv27Nnq2rWrJKlZs2ZKTEzUxo0bFRYWprFjxyo8PFyjR4+29q9SpYok6ciRI/rqq6+0YcMGhYWFSZJKly5t9/Fv3bqlL774QkWKFLG2Pffcc2lqLFq0qA4ePKhKlSpp/vz5unTpknbv3i0fHx9JUlBQkLV/79691b9/f02cOFEuLi7at2+fYmNjtWzZMrvrAwDkPGZ6AQBAphw+fFi7du1SeHi4JMnR0VHPP/+85syZI0mKjY1V48aN0903NjZW+fLlU2ho6EPVEBAQYBN4JenYsWN64YUXVLp0aXl5eemxxx6TJJ0+fdp67GrVqlkD79+1a9dOjo6OWr58uSRpzpw5evrppxUYGPhQtQIAcgYzvQAAIFNmz56tO3fuqESJEtY2wzDk5OSkK1euyM3N7Z773m+bJDk4OKR5f/b27dtp+uXPnz9NW+vWreXv76+ZM2eqePHiSklJUaVKlXTr1q0MHdvZ2VndunVTZGSk2rdvr/nz52vy5Mn33QcAkHsx0wsAAOx2584d/fe//9VHH32k2NhY62ffvn0KCAjQvHnzVLlyZW3cuDHd/UNCQpSSkqLo6Oh0txcpUkTXrl1TUlKStS31nd37uXz5sg4dOqS3335bjRs3VoUKFXTlyhWbPpUrV1ZsbKz++OOPe47Tu3dvfffdd5o2bZpu375tswAXACBvYaYXAADYbfXq1bpy5Yp69eolb29vm20dOnTQ7NmzNWnSJDVu3FhlypRReHi47ty5o7Vr12rIkCEKDAxUjx49FBERoSlTpqhKlSo6deqULl68qE6dOqlOnTpyd3fX8OHD9corr2jXrl1pVoZOT8GCBVWoUCF9/vnn8vPz0+nTpzVs2DCbPp07d9Z//vMftWvXTuPGjZOfn59iYmJUvHhx1a1bV5JUoUIFPfHEExo6dKgiIiIeODsMAMi9mOkFAAB2mz17tsLCwtIEXunuQlKxsbHy8vLS4sWLtXLlSlWtWlWNGjXSzp07rf0+++wzdejQQS+99JKCg4PVp08f68yuj4+PvvzyS61Zs0YhISFasGCBRo0a9cC6HBwctHDhQu3du1eVKlXSoEGDNGHCBJs+zs7OWr9+vYoWLaoWLVooJCRE77//vvLly2fTr1evXrp165YiIiIycYUAALmFxeAL5wAAANIYO3asFi5cqAMHDuR0KQCAh8BMLwAAwF8kJiZq9+7dmjp1qgYOHJjT5QAAHhKhFwAA4C8GDBigJ598UqGhoTzaDAAmwOPNAAAAAADTYqYXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACYFqEXAAAAAGBahF4AAAAAgGkRegEAAAAApkXoBQAAAACY1v8BQuqWXdwnN/8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,5],dpi = 100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Algorithm')\n",
    "sns.barplot(x = acc,y = model,palette='dark');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree --> 0.9717514124293786\n",
      "Naive Bayes --> 0.9943502824858758\n",
      "SVM --> 0.9858757062146892\n",
      "Logistic Regression --> 0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "accuracy_models = dict(zip(model, acc))\n",
    "for k, v in accuracy_models.items():\n",
    "    print (k, '-->', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This prints the accuracy of each model used here and we can see Naive Bayes performing the best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "All models have been tuned and saved.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize models with a fixed random state for reproducibility\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "nb_model = GaussianNB()\n",
    "svm_model = SVC(random_state=42)\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "# For Decision Tree, we're tuning max_depth and min_samples_split\n",
    "# For SVC, we're tuning C (regularization parameter) and the kernel type\n",
    "# For Logistic Regression, we're tuning C and the penalty type\n",
    "# Note: GaussianNB doesn't have significant hyperparameters for tuning in this context\n",
    "param_grid = {\n",
    "    dt_model: {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]},\n",
    "    nb_model: {},  # Empty as we're not tuning GaussianNB\n",
    "    svm_model: {'C': [0.1, 1, 10], 'kernel': ['rbf', 'poly']},\n",
    "    lr_model: {'C': [0.1, 1, 10], 'penalty': ['l2']},\n",
    "}\n",
    "\n",
    "# Dictionary to store the best models after tuning\n",
    "best_models = {}\n",
    "\n",
    "# Perform Grid Search for each model\n",
    "for model, params in param_grid.items():\n",
    "    grid_search = GridSearchCV(model, params, cv=3, n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(Xtrain, Ytrain)  # Fit grid search to find the best hyperparameters\n",
    "    best_model = grid_search.best_estimator_  # Best model after tuning\n",
    "    best_models[model.__class__.__name__] = best_model  # Store the best model\n",
    "    \n",
    "    # Save the best model to a file using pickle for later use\n",
    "    with open(f'{model.__class__.__name__}_model.pkl', 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "\n",
    "# Indicate completion of tuning and saving models\n",
    "print(\"All models have been tuned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier: 0.9859\n",
      "Accuracy of GaussianNB: 0.9944\n",
      "Accuracy of SVC: 0.9887\n",
      "Accuracy of LogisticRegression: 0.9887\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Model names\n",
    "model_names = ['DecisionTreeClassifier', 'GaussianNB', 'SVC', 'LogisticRegression']\n",
    "\n",
    "# Load each model and evaluate its accuracy\n",
    "for model_name in model_names:\n",
    "    # Load the tuned model from its .pkl file\n",
    "    with open(f'{model_name}_model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(Xtest)  # Ensure X_test is your test feature data\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(Ytest, y_pred)  # Ensure y_test is your actual test labels\n",
    "    print(f'Accuracy of {model_name}: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decision Tree\n",
    "\n",
    "- Before Tuning: 0.9718 (97.18%)\n",
    "- After Tuning: 0.9859 (98.59%)\n",
    "- Change: The accuracy increased by approximately 1.41%. This improvement suggests that tuning hyperparameters like max_depth, min_samples_split, and criterion helped the model to better generalize, reducing overfitting or underfitting.\n",
    "\n",
    "\n",
    "2. Naive Bayes\n",
    "\n",
    "- Before Tuning: 0.9944 (99.44%)\n",
    "- After Tuning: 0.9944 (99.44%)\n",
    "- Change: There is no change in accuracy. This is expected as Gaussian Naive Bayes generally has fewer hyperparameters that significantly impact its performance.\n",
    "\n",
    "\n",
    "3. SVM\n",
    "\n",
    "- Before Tuning: 0.9859 (98.59%)\n",
    "- After Tuning: 0.9887 (98.87%)\n",
    "- Change: The accuracy increased slightly by approximately 0.28%. This improvement, though modest, suggests that adjusting hyperparameters like C, kernel, and gamma helped in fine-tuning the model's performance.\n",
    "\n",
    "\n",
    "4. Logistic Regression\n",
    "\n",
    "- Before Tuning: 0.9774 (97.74%)\n",
    "- After Tuning: 0.9887 (98.87%)\n",
    "- Change: There's a significant increase in accuracy by approximately 1.13%. Tuning parameters like C and penalty likely contributed to this improvement, enhancing the model's ability to fit the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - Training Accuracy: 0.9965, Test Accuracy: 0.9859\n",
      "Confusion Matrix for DecisionTreeClassifier:\n",
      "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 19  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "Classification Report for DecisionTreeClassifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       0.93      1.00      0.96        13\n",
      "   blackgram       0.95      1.00      0.97        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      0.96      0.98        26\n",
      "        jute       1.00      0.86      0.92        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      0.95      0.97        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       0.88      1.00      0.93         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      0.89      0.94         9\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.67      1.00      0.80         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.97      0.98      0.97       354\n",
      "weighted avg       0.99      0.99      0.99       354\n",
      "\n",
      "\n",
      "GaussianNB - Training Accuracy: 0.9894, Test Accuracy: 0.9944\n",
      "Confusion Matrix for GaussianNB:\n",
      "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "Classification Report for GaussianNB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       1.00      1.00      1.00        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       1.00      0.86      0.92        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      1.00      1.00        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      1.00      1.00         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      1.00      1.00        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       0.67      1.00      0.80         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.98      0.99      0.99       354\n",
      "weighted avg       1.00      0.99      0.99       354\n",
      "\n",
      "\n",
      "SVC - Training Accuracy: 0.9915, Test Accuracy: 0.9887\n",
      "Confusion Matrix for SVC:\n",
      "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 18  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "Classification Report for SVC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       0.90      1.00      0.95        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       0.93      1.00      0.97        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      0.90      0.95        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       0.88      1.00      0.93         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      0.95      0.97        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       1.00      0.75      0.86         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.99      0.98      0.98       354\n",
      "weighted avg       0.99      0.99      0.99       354\n",
      "\n",
      "\n",
      "LogisticRegression - Training Accuracy: 0.9844, Test Accuracy: 0.9887\n",
      "Confusion Matrix for LogisticRegression:\n",
      "[[13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
      "\n",
      "Classification Report for LogisticRegression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      banana       1.00      1.00      1.00        13\n",
      "   blackgram       0.83      1.00      0.90        19\n",
      "    chickpea       1.00      1.00      1.00        13\n",
      "     coconut       1.00      1.00      1.00        20\n",
      "      coffee       1.00      1.00      1.00        23\n",
      "      cotton       1.00      1.00      1.00        26\n",
      "        jute       1.00      1.00      1.00        14\n",
      " kidneybeans       1.00      1.00      1.00        19\n",
      "      lentil       1.00      0.95      0.97        20\n",
      "       maize       1.00      1.00      1.00        20\n",
      "       mango       1.00      1.00      1.00        13\n",
      "   mothbeans       1.00      0.86      0.92         7\n",
      "    mungbean       1.00      1.00      1.00        29\n",
      "   muskmelon       1.00      1.00      1.00        21\n",
      "      orange       1.00      1.00      1.00        25\n",
      "      papaya       1.00      1.00      1.00         9\n",
      "  pigeonpeas       1.00      0.90      0.95        20\n",
      " pomegranate       1.00      1.00      1.00        20\n",
      "        rice       1.00      1.00      1.00         4\n",
      "  watermelon       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       354\n",
      "   macro avg       0.99      0.99      0.99       354\n",
      "weighted avg       0.99      0.99      0.99       354\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from math import sqrt\n",
    "\n",
    "# Assuming you have classification problem\n",
    "for model_name in model_names:\n",
    "    with open(f'{model_name}_model.pkl', 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(Xtrain)  # Training predictions\n",
    "    y_pred_test = model.predict(Xtest)  # Test predictions\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy_train = accuracy_score(Ytrain, y_pred_train)\n",
    "    accuracy_test = accuracy_score(Ytest, y_pred_test)\n",
    "    \n",
    "    # Overfitting/Underfitting Assessment\n",
    "    print(f'{model_name} - Training Accuracy: {accuracy_train:.4f}, Test Accuracy: {accuracy_test:.4f}')\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(Ytest, y_pred_test)\n",
    "    print(f'Confusion Matrix for {model_name}:\\n{cm}\\n')\n",
    "\n",
    "    # Classification Report\n",
    "    print(f'Classification Report for {model_name}:\\n{classification_report(Ytest, y_pred_test)}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The detailed results you've provided for each model allow for a thorough evaluation of their performance. Let's break down and interpret the information for each model:\n",
    "\n",
    "### 1. DecisionTreeClassifier\n",
    "- Training Accuracy: 0.9965 (99.65%)\n",
    "- Test Accuracy: 0.9859 (98.59%)\n",
    "#### Confusion Matrix and Classification Report:\n",
    "- The model performs exceptionally well on most classes with high precision, recall, and F1-scores.\n",
    "- The confusion matrix shows correct classification across almost all classes.\n",
    "- The slight discrepancy between training and test accuracy suggests a very minor overfitting but is generally acceptable.\n",
    "\n",
    "### 2. GaussianNB\n",
    "- Training Accuracy: 0.9894 (98.94%)\n",
    "- Test Accuracy: 0.9944 (99.44%)\n",
    "#### Confusion Matrix and Classification Report:\n",
    "- GaussianNB also shows excellent performance, with high scores across all metrics.\n",
    "- The test accuracy is slightly higher than the training accuracy, which is unusual but may indicate that the test set characteristics align well with the model's strengths.\n",
    "\n",
    "### 3. SVC\n",
    "- Training Accuracy: 0.9915 (99.15%)\n",
    "- Test Accuracy: 0.9887 (98.87%)\n",
    "#### Confusion Matrix and Classification Report:\n",
    "- The SVM model demonstrates strong performance with high accuracy and balanced precision, recall, and F1-scores across all classes.\n",
    "- The slight drop in test accuracy compared to training accuracy is normal and indicates good generalization.\n",
    "\n",
    "### 4. LogisticRegression\n",
    "- Training Accuracy: 0.9844 (98.44%)\n",
    "- Test Accuracy: 0.9887 (98.87%)\n",
    "#### Confusion Matrix and Classification Report:\n",
    "- Logistic Regression performs well with high scores across precision, recall, and F1-score.\n",
    "- The model's test accuracy is on par with its training accuracy, indicating effective generalization to unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Test Accuracy: 0.9831\n",
      "GaussianNB Test Accuracy: 0.9944\n",
      "SVC Test Accuracy: 0.9887\n",
      "LogisticRegression Test Accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "# DecisionTreeClassifier: tuning max_depth, min_samples_split, and criterion\n",
    "# GaussianNB: not tuning any parameters as it typically doesn't require it\n",
    "# SVC: tuning C (regularization parameter), kernel type, and gamma\n",
    "# LogisticRegression: tuning C (regularization strength), solver, and penalty\n",
    "models_params = {\n",
    "    DecisionTreeClassifier: {\n",
    "        'max_depth': [3, 5, 10, None],\n",
    "        'min_samples_split': [2, 4, 6, 8],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    GaussianNB: {},  # No parameters to tune for GaussianNB in this setup\n",
    "    SVC: {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'rbf', 'poly'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    LogisticRegression: {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'penalty': ['l2', 'none']  # 'none' is for no regularization\n",
    "    },\n",
    "}\n",
    "\n",
    "def perform_randomized_search(models_params, Xtrain, Ytrain):\n",
    "    best_models = {}\n",
    "\n",
    "    # Iterating through each model and their hyperparameter grid\n",
    "    for model_class, params in models_params.items():\n",
    "        # Instantiate the model\n",
    "        model = model_class()\n",
    "\n",
    "        # Set up the randomized search with cross-validation\n",
    "        random_search = RandomizedSearchCV(\n",
    "            model,\n",
    "            params,\n",
    "            n_iter=10,  # Trying out 10 different combinations\n",
    "            cv=5,  # 5-fold cross-validation\n",
    "            random_state=42,  # For reproducibility\n",
    "            n_jobs=-1  # Utilize all available CPU cores\n",
    "        )\n",
    "\n",
    "        # Fit randomized search to find the best hyperparameters\n",
    "        random_search.fit(Xtrain, Ytrain)\n",
    "\n",
    "        # Store the best performing model variant\n",
    "        best_models[model_class.__name__] = random_search.best_estimator_\n",
    "\n",
    "    return best_models\n",
    "\n",
    "# Perform hyperparameter tuning and store best models\n",
    "best_models = perform_randomized_search(models_params, Xtrain, Ytrain)\n",
    "\n",
    "# Evaluate and print the accuracy of each best model on the test set\n",
    "for model_name, model in best_models.items():\n",
    "    # Predict on test data and calculate accuracy\n",
    "    test_accuracy = accuracy_score(Ytest, model.predict(Xtest))\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DecisionTreeClassifier:\n",
    "\n",
    "- Randomized Search Accuracy: 0.9831\n",
    "- Grid Search Accuracy: 0.9859\n",
    "- Best: Grid Search (0.9859)\n",
    "    \n",
    "2. GaussianNB:\n",
    "\n",
    "- Randomized Search Accuracy: 0.9944\n",
    "- Grid Search Accuracy: 0.9944\n",
    "- Best: Both methods yield the same accuracy.\n",
    "\n",
    "3. SVC:\n",
    "\n",
    "- Randomized Search Accuracy: 0.9887\n",
    "- Grid Search Accuracy: 0.9887\n",
    "- Best: Both methods yield the same accuracy.\n",
    "    \n",
    "4. LogisticRegression:\n",
    "\n",
    "- Randomized Search Accuracy: 0.9887\n",
    "- Grid Search Accuracy: 0.9887\n",
    "- Best: Both methods yield the same accuracy.\n",
    "\n",
    "#### Here's a brief explanation:\n",
    "\n",
    "1. Hyperparameter Tuning Process:\n",
    "\n",
    "- Randomized SearchCV: This method randomly samples from a range of hyperparameters, providing a quick and efficient way to discover the best parameters for the model. It's especially useful when the search space is large.\n",
    "- Grid SearchCV: This method exhaustively tries all possible combinations from a specified range of hyperparameters. It's more thorough than Randomized Search and can often find the best combination, but at a higher computational cost.\n",
    "\n",
    "2. Model Improvement:\n",
    "\n",
    "- DecisionTreeClassifier: The Grid Search method slightly improved the accuracy of the Decision Tree model. This improvement indicates that the exhaustive search helped fine-tune crucial parameters like tree depth and splitting criteria, resulting in a model that better captures the patterns in the data without overfitting.\n",
    "- GaussianNB: As Gaussian Naive Bayes usually doesn't involve extensive hyperparameter tuning, its performance remained consistent, showcasing its efficiency with the given dataset.\n",
    "- SVC and LogisticRegression: Both models maintained high accuracy across both tuning methods. This consistency suggests that the initial choice of parameters was already quite effective, and both Randomized and Grid Search fine-tuned these models to optimize their performance.\n",
    "\n",
    "###### Conclusion:\n",
    "\n",
    "The process of hyperparameter tuning, both through Randomized Search and Grid Search, led to the identification of the most optimal set of parameters for each model. This optimization tailored each model more precisely to the dataset, resulting in improved accuracy and, consequently, a more reliable predictive performance.\n",
    "The tuning also helps in mitigating issues like overfitting or underfitting, ensuring the models generalize well to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Accuracy: 0.9859\n",
      "GaussianNB Accuracy: 0.9944\n",
      "SVC Accuracy: 0.9887\n",
      "LogisticRegression Accuracy: 0.9887\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have not yet defined these lists\n",
    "model_names = []\n",
    "accuracies = []\n",
    "\n",
    "# Append DecisionTreeClassifier\n",
    "model_names.append('DecisionTreeClassifier')\n",
    "accuracies.append(0.9859)  # Grid Search result\n",
    "\n",
    "# Append GaussianNB\n",
    "model_names.append('GaussianNB')\n",
    "accuracies.append(0.9944)  # Equal in both methods\n",
    "\n",
    "# Append SVC\n",
    "model_names.append('SVC')\n",
    "accuracies.append(0.9887)  # Equal in both methods\n",
    "\n",
    "# Append LogisticRegression\n",
    "model_names.append('LogisticRegression')\n",
    "accuracies.append(0.9887)  # Equal in both methods\n",
    "\n",
    "# Printing the models and their accuracies\n",
    "for m, a in zip(model_names, accuracies):\n",
    "    print(f\"{m} Accuracy: {a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Test Accuracy: 0.9831\n",
      "GaussianNB Test Accuracy: 0.9944\n",
      "SVC Test Accuracy: 0.9887\n",
      "LogisticRegression Test Accuracy: 0.9887\n",
      "\n",
      "The best model is GaussianNB with an accuracy of 0.9944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Perform Randomized Search and evaluate each model\n",
    "model_accuracies = {}\n",
    "for model_name, model in best_models.items():\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    test_accuracy = accuracy_score(Ytest, model.predict(Xtest))\n",
    "    model_accuracies[model_name] = test_accuracy\n",
    "    print(f\"{model_name} Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Determine the best model based on test accuracy\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "best_accuracy = model_accuracies[best_model_name]\n",
    "\n",
    "print(f\"\\nThe best model is {best_model_name} with an accuracy of {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Predictions:\n",
      "Class banana: 1.0\n",
      "Class rice: 0.0\n",
      "Class blackgram: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming you have already trained your Random Forest model (RF)\n",
    "# Example training:\n",
    "# RF.fit(X_train, y_train)\n",
    "\n",
    "# Your input data\n",
    "data = np.array([[4, 1, 80, 2.63016, 0.3, 6.7, 0.91]])\n",
    "\n",
    "# Get probability estimates for each class\n",
    "probabilities = NaiveBayes.predict_proba(data)\n",
    "\n",
    "# Get the indices of the top 3 probabilities\n",
    "top3_indices = np.argsort(probabilities[0])[::-1][:3]\n",
    "\n",
    "# Get the corresponding class labels\n",
    "top3_labels = NaiveBayes.classes_[top3_indices]\n",
    "\n",
    "print(\"Top 3 Predictions:\")\n",
    "for index, label in zip(top3_indices, top3_labels):\n",
    "    print(f\"Class {label}: {probabilities[0][index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.2.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model (GaussianNB) has been saved to best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Assuming the best model is stored in best_models[best_model_name]\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Define the filename for saving the model\n",
    "model_filename = 'best_model.pkl'\n",
    "\n",
    "# Save the best model using joblib\n",
    "joblib.dump(best_model, model_filename)\n",
    "\n",
    "print(f\"The best model ({best_model_name}) has been saved to {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
